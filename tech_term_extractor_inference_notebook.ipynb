{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tech_term_extractor_m2_v3.ipynb","provenance":[{"file_id":"1f4F920UnRog3p9xODbq2-6nxiOUlRuws","timestamp":1613349820408},{"file_id":"1b9rX1lUlWdCO_g_49QUzvhcPB6naqmYa","timestamp":1612164334062}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"rruUxgIfzJNc"},"source":["## 1. Connect to google drive\r\n","\r\n","\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"MeDx78jhuiug","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615777226045,"user_tz":240,"elapsed":22035,"user":{"displayName":"Shelley","photoUrl":"","userId":"14412474700598300757"}},"outputId":"beef7d4b-02d9-48dd-921e-3c30256c74bd"},"source":["# click the link, sign in and copy/paste code to get access to your google drive\r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f6W3Z2zmz5NL"},"source":["## 2. Import packages"]},{"cell_type":"code","metadata":{"id":"SxgUW5HhucH4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615777245757,"user_tz":240,"elapsed":12714,"user":{"displayName":"Shelley","photoUrl":"","userId":"14412474700598300757"}},"outputId":"962059ae-9f49-4332-f9c6-f8d8b164a7b5"},"source":["! pip install transformers\r\n","import torch\r\n","import pandas as pd\r\n","import numpy as np\r\n","from transformers import AutoTokenizer, AutoModelForTokenClassification\r\n","from torch.utils.data import TensorDataset,DataLoader, SequentialSampler\r\n","import nltk\r\n","nltk.download('punkt')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n","\u001b[K     |████████████████████████████████| 1.9MB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 47.2MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 55.0MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=42c681d3ad63fe18bc19278a956307ce093a8845cc3321e1393a32ea68c1b13b\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"yJf43ldi-uuT"},"source":["## 3. tech_term_extractor: detect_tech_terms_in_articles_csv()\r\n","The function reads a csv file with one column \"text\" containing articles. One article each row. \r\n","\r\n","It returns a dataframe with two columns \"text\" and \"tech terms\" containing the articles and the predicted tech terms respectively. One article and a list of identified tech terms each row. "]},{"cell_type":"code","metadata":{"id":"0-ZyPenjaTlm","executionInfo":{"status":"ok","timestamp":1615777250166,"user_tz":240,"elapsed":961,"user":{"displayName":"Shelley","photoUrl":"","userId":"14412474700598300757"}}},"source":["BATCH_SIZE = 8\r\n","NUM_WORKERS = 1\r\n","def detect_tech_terms_in_articles_csv(articles_csv, model_and_tokenizers_dir):\r\n","    df_articles = pd.read_csv(articles_csv)\r\n","    df_articles['tokens'] = df_articles['text'].apply(lambda x : nltk.word_tokenize(x))\r\n","    df_articles['tokenized_text'] = df_articles['tokens'].apply(lambda x : ' '.join(x))\r\n","    df_articles['length'] = df_articles['text'].apply(lambda x : len(nltk.word_tokenize(x)) )\r\n","    #set length thresholds and splitting text accordingly\r\n","    threshold1 = 420;threshold2 = 1260;threshold3 = 4200;threshold4 = 8400 \r\n","\r\n","    def tech_term_detector(articles):\r\n","      #device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #try to use GPU.If not, use CPU\r\n","      #device = torch.device(\"cpu\")\r\n","      device = torch.device(\"cuda\") \r\n","      loaded_model = AutoModelForTokenClassification.from_pretrained(model_and_tokenizers_dir)\r\n","      loaded_model = loaded_model.to(device)\r\n","      loaded_tokenizer = AutoTokenizer.from_pretrained(model_and_tokenizers_dir)\r\n","      label_map_reverse = {2: 'B-tech', 1:'I-tech', 0:'O'}\r\n","      loaded_model.eval()\r\n","      total_tech_terms = []\r\n","      predictions = []\r\n","      new_labels_for_articles = []\r\n","      new_tokens_for_articles = []\r\n","\r\n","      pt_articles = loaded_tokenizer(articles, padding=True, truncation=True,return_tensors=\"pt\", is_split_into_words=False)\r\n","      input_ids = torch.stack(tuple(pt_articles['input_ids']), dim=0)\r\n","      attention_masks = torch.stack(tuple(pt_articles['attention_mask']), dim=0)\r\n","      dataset = TensorDataset(input_ids, attention_masks)\r\n","      dataloader = DataLoader(dataset, sampler = SequentialSampler(dataset),batch_size = BATCH_SIZE, num_workers=NUM_WORKERS)\r\n","      for batch in dataloader:\r\n","        batch = tuple(t.to(device) for t in batch)\r\n","        b_input_ids, b_input_mask= batch\r\n","        with torch.no_grad():\r\n","          outputs = loaded_model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\r\n","          logits = outputs[0]\r\n","          logits = logits.detach().cpu().numpy()\r\n","          predictions.append(logits)\r\n","\r\n","      all_predictions = np.concatenate(predictions, axis=0)\r\n","      predicted_label_ids = np.argmax(all_predictions, axis=2)\r\n","      \r\n","      #merging sub-tokens to words for all articles\r\n","      for num, predicted_label_id in enumerate(predicted_label_ids):\r\n","        tokenized_article = loaded_tokenizer.convert_ids_to_tokens(pt_articles[\"input_ids\"][num]) \r\n","        new_tokens = []\r\n","        new_labels = []\r\n","        #within one article\r\n","        for token, label_idx in zip(tokenized_article, predicted_label_id):\r\n","          if (token != \"[CLS]\" and token !=\"[SEP]\" and token !=\"[PAD]\"):\r\n","            if token.startswith('##'):\r\n","                new_tokens[-1] = new_tokens[-1] + token[2:]\r\n","            else:\r\n","                new_labels.append(label_map_reverse[label_idx])\r\n","                new_tokens.append(token)\r\n","        new_labels_for_articles.append(new_labels)\r\n","        new_tokens_for_articles.append(new_tokens)\r\n","\r\n","      for (new_tokens_for_article, new_labels_for_article) in zip(new_tokens_for_articles, new_labels_for_articles):\r\n","        tech_terms = []\r\n","        for index, (word,label) in enumerate(zip(new_tokens_for_article, new_labels_for_article)):\r\n","          if label == 'B-tech':\r\n","            if index !=0:\r\n","              if new_labels_for_article[index-1] != 'O': #if previous word's label is B or I, then combine words to a phrase\r\n","                tech_terms[-1] = tech_terms[-1]+\" \"+word\r\n","              else:  \r\n","                tech_terms.append(word)\r\n","            else:\r\n","                tech_terms.append(word)        \r\n","          elif label == 'I-tech':\r\n","            if index == 0:\r\n","              tech_terms.append(word)\r\n","            else:\r\n","              if new_labels_for_article[index-1] != 'O':\r\n","                tech_terms[-1] = tech_terms[-1]+\" \"+ word\r\n","              else:\r\n","                tech_terms.append(word)\r\n","        total_tech_terms.append(tech_terms)\r\n","      return total_tech_terms\r\n","\r\n","    # for articles under threshold\r\n","    df_under_thre = df_articles[df_articles['length']<=threshold1]\r\n","    if df_under_thre.empty == False:\r\n","        tech_terms_under = tech_term_detector(df_under_thre.tokenized_text.tolist())\r\n","        df_tech_terms_under = pd.DataFrame(zip(df_under_thre.index,df_under_thre.tokenized_text.tolist(),tech_terms_under),columns=['NO.','text','tech_terms']) #.set_index(data.iloc[:, 0])\r\n","        df_tech_terms_under1 = df_tech_terms_under.drop(['NO.'], axis=1, inplace=False)\r\n","    else:\r\n","        pass\r\n","\r\n","    def split_combine_output(df, num_split):      \r\n","        splited_sents = []\r\n","        for row_index, row in df.iterrows():\r\n","            for i in range(num_split):\r\n","                sents  = ' '.join(row['tokens'][round(row['length']*i/num_split):round(row['length']*(i+1)/num_split)])\r\n","                splited_sents.append(sents)\r\n","                \r\n","        tech_terms = tech_term_detector(splited_sents)\r\n","        index_inter = [[str(index) for index in df.index],[str(num) for num in list(range(num_split))]]\r\n","        mul_index = pd.MultiIndex.from_product(index_inter, names=[\"NO.\", \"split_index\"])\r\n","        df_tech_terms = pd.DataFrame(zip(splited_sents,tech_terms), index = mul_index, columns=['text','tech_terms'])\r\n","        df_tech_terms = df_tech_terms.groupby(level='NO.').agg(text = pd.NamedAgg(column ='text',aggfunc= sum), tech_terms = pd.NamedAgg(column = 'tech_terms', aggfunc = sum)).reset_index() #.reset_index(name = 'index')      \r\n","        df_tech_terms1 = df_tech_terms.drop(['NO.'], axis=1, inplace=False)\r\n","        return df_tech_terms,df_tech_terms1\r\n","\r\n","\r\n","    # for articles b/w threshold1 and threshold2\r\n","    df_bw_thre1 = df_articles[(df_articles['length']>threshold1)&(df_articles['length']<=threshold2)]\r\n","    if df_bw_thre1.empty == False:\r\n","       df_tech_terms_bw1, df_tech_terms_bw11 =split_combine_output(df_bw_thre1, 3)\r\n","    else:\r\n","        pass\r\n","    # for articles b/w threshold2 and threshold3\r\n","    df_bw_thre2 = df_articles[(df_articles['length']>threshold2)&(df_articles['length']<=threshold3)]\r\n","    if df_bw_thre2.empty == False:\r\n","       df_tech_terms_bw2, df_tech_terms_bw21 =split_combine_output(df_bw_thre2, 10)\r\n","    else:\r\n","        pass\r\n","    # for articles b/w threshold3 and threshold4\r\n","    df_bw_thre3 = df_articles[(df_articles['length']>threshold3)&(df_articles['length']<=threshold4)]\r\n","    if df_bw_thre3.empty == False:\r\n","       df_tech_terms_bw3, df_tech_terms_bw31 =split_combine_output(df_bw_thre3, 20)\r\n","    else:\r\n","        pass\r\n","    # for articles over threshold4 (up to maximum 33600)\r\n","    df_over_thre = df_articles[df_articles['length']>threshold4]\r\n","    if df_over_thre.empty == False:  \r\n","       df_tech_terms_over, df_tech_terms_over1 =split_combine_output(df_over_thre, 80)\r\n","    else:\r\n","        pass\r\n","    \r\n","    def combine_tech_term_dfs(tuple_dfs):    \r\n","        df_tech_terms= pd.DataFrame(np.concatenate(tuple_dfs,axis = 0), columns= ['NO.','text', 'tech_terms'])\r\n","        df_tech_terms['NO.'] = df_tech_terms['NO.'].astype('int')\r\n","        df_tech_terms.sort_values(by=['NO.'], inplace=True)\r\n","        df_tech_terms.drop(['NO.'], axis=1, inplace=True)\r\n","        return df_tech_terms\r\n","    \r\n","    #c(5,5)\r\n","    if df_under_thre.empty == False and df_bw_thre1.empty == False and df_bw_thre2.empty == False and df_bw_thre3.empty == False and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under, df_tech_terms_bw1,df_tech_terms_bw2,df_tech_terms_bw3,df_tech_terms_over))\r\n","        return df_tech_terms_full\r\n","    #c(5,4)\r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == False and df_bw_thre2.empty == False and df_bw_thre3.empty == False and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_bw1,df_tech_terms_bw2,df_tech_terms_bw3,df_tech_terms_over))\r\n","        return df_tech_terms_full    \r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == True and df_bw_thre2.empty == False and df_bw_thre3.empty == False and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under,df_tech_terms_bw2,df_tech_terms_bw3,df_tech_terms_over))\r\n","        return df_tech_terms_full\r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == False and df_bw_thre2.empty == True and df_bw_thre3.empty == False and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under,df_tech_terms_bw1,df_tech_terms_bw3,df_tech_terms_over))\r\n","        return df_tech_terms_full\r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == False and df_bw_thre2.empty == False and df_bw_thre3.empty == True and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under,df_tech_terms_bw1,df_tech_terms_bw2,df_tech_terms_over))\r\n","        return df_tech_terms_full\r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == False and df_bw_thre2.empty == False and df_bw_thre3.empty == False and df_over_thre.empty == True:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under,df_tech_terms_bw1,df_tech_terms_bw2,df_tech_terms_bw3))\r\n","        return df_tech_terms_full\r\n","    #c(5,3)\r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == False and df_bw_thre2.empty == False and df_bw_thre3.empty == True and df_over_thre.empty == True:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under,df_tech_terms_bw1,df_tech_terms_bw2))\r\n","        return df_tech_terms_full  \r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == False and df_bw_thre2.empty == True and df_bw_thre3.empty == False and df_over_thre.empty == True:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under, df_tech_terms_bw1,df_tech_terms_bw3))\r\n","        return df_tech_terms_full  \r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == False and df_bw_thre2.empty == True and df_bw_thre3.empty == True and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under,df_tech_terms_bw1,df_tech_terms_over))\r\n","        return df_tech_terms_full  \r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == True and df_bw_thre2.empty == False and df_bw_thre3.empty == False and df_over_thre.empty == True:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under,df_tech_terms_bw2,df_tech_terms_bw3))\r\n","        return df_tech_terms_full  \r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == True and df_bw_thre2.empty == False and df_bw_thre3.empty == True and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under,df_tech_terms_bw2,df_tech_terms_over))\r\n","        return df_tech_terms_full  \r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == True and df_bw_thre2.empty == True and df_bw_thre3.empty == False and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under,df_tech_terms_bw3,df_tech_terms_over))\r\n","        return df_tech_terms_full\r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == False and df_bw_thre2.empty == False and df_bw_thre3.empty == False and df_over_thre.empty == True:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_bw1,df_tech_terms_bw2,df_tech_terms_bw3))\r\n","        return df_tech_terms_full\r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == False and df_bw_thre2.empty == False and df_bw_thre3.empty == True and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_bw1,df_tech_terms_bw2,df_tech_terms_over))\r\n","        return df_tech_terms_full\r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == False and df_bw_thre2.empty == True and df_bw_thre3.empty == False and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_bw1,df_tech_terms_bw3,df_tech_terms_over))\r\n","        return df_tech_terms_full\r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == True and df_bw_thre2.empty == False and df_bw_thre3.empty == False and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_bw2,df_tech_terms_bw3, df_tech_terms_over))\r\n","        return df_tech_terms_full\r\n","    #c(5,2)\r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == False and df_bw_thre2.empty == True and df_bw_thre3.empty == True and df_over_thre.empty == True:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under,df_tech_terms_bw1))\r\n","        return df_tech_terms_full  \r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == True and df_bw_thre2.empty == False and df_bw_thre3.empty == True and df_over_thre.empty == True:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under, df_tech_terms_bw2))\r\n","        return df_tech_terms_full  \r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == True and df_bw_thre2.empty == True and df_bw_thre3.empty == False and df_over_thre.empty == True:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under,df_tech_terms_bw3))\r\n","        return df_tech_terms_full  \r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == True and df_bw_thre2.empty == True and df_bw_thre3.empty == True and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_under,df_tech_terms_over))\r\n","        return df_tech_terms_full  \r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == False and df_bw_thre2.empty == False and df_bw_thre3.empty == True and df_over_thre.empty == True:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_bw1,df_tech_terms_bw2))\r\n","        return df_tech_terms_full  \r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == False and df_bw_thre2.empty == True and df_bw_thre3.empty == False and df_over_thre.empty == True:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_bw1,df_tech_terms_bw3))\r\n","        return df_tech_terms_full\r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == False and df_bw_thre2.empty == True and df_bw_thre3.empty == True and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_bw1,df_tech_terms_over))\r\n","        return df_tech_terms_full\r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == True and df_bw_thre2.empty == False and df_bw_thre3.empty == False and df_over_thre.empty == True:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_bw2,df_tech_terms_bw3))\r\n","        return df_tech_terms_full\r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == True and df_bw_thre2.empty == False and df_bw_thre3.empty == True and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_bw2,df_tech_terms_over))\r\n","        return df_tech_terms_full\r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == True and df_bw_thre2.empty == True and df_bw_thre3.empty == False and df_over_thre.empty == False:\r\n","        df_tech_terms_full = combine_tech_term_dfs((df_tech_terms_bw3, df_tech_terms_over))\r\n","        return df_tech_terms_full\r\n","    #c(5,1)\r\n","    elif df_under_thre.empty == False and df_bw_thre1.empty == True and df_bw_thre2.empty == True and df_bw_thre3.empty == True and df_over_thre.empty == True:\r\n","        return df_tech_terms_under1    \r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == False and df_bw_thre2.empty == True and df_bw_thre3.empty == True and df_over_thre.empty == True:\r\n","        return df_tech_terms_bw11\r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == True and df_bw_thre2.empty == False and df_bw_thre3.empty == True and df_over_thre.empty == True:\r\n","        return df_tech_terms_bw21\r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == True and df_bw_thre2.empty == True and df_bw_thre3.empty == False and df_over_thre.empty == True:\r\n","        return df_tech_terms_bw31\r\n","    elif df_under_thre.empty == True and df_bw_thre1.empty == True and df_bw_thre2.empty == True and df_bw_thre3.empty == True and df_over_thre.empty == False:\r\n","        return df_tech_terms_over1\r\n","    else:\r\n","        print(\"Can't find any articles in the csv file.\")\r\n","\r\n","    return "],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OYmZD8Dze7tJ"},"source":["## 4. test on the news articles"]},{"cell_type":"code","metadata":{"id":"iH6qKXqBD1y4"},"source":["input_dir = \"gdrive/My Drive/ner_tech_proj/saved_bert_model_and_tokenizer_m2_v12/\"\r\n","df_news = \"gdrive/My Drive/ner_tech_proj/data/all_untagged_data/test/test_model15.csv\"\r\n","df_test_tech_terms_news = detect_tech_terms_in_articles_csv(df_news, input_dir)\r\n","df_test_tech_terms_news.to_csv('gdrive/My Drive/ner_tech_proj/data/all_untagged_data/test/test_model15_pred_tech_terms.csv', index= False ,encoding='utf-8-sig')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Db5ff0SqGStB"},"source":["input_dir = \"gdrive/My Drive/ner_tech_proj/saved_bert_model_and_tokenizer_m2_v13/\"\r\n","df_news = \"gdrive/My Drive/ner_tech_proj/data/all_untagged_data/test/test-m.csv\"\r\n","df_test_tech_terms_news = detect_tech_terms_in_articles_csv(df_news, input_dir)\r\n","df_test_tech_terms_news.to_csv('gdrive/My Drive/ner_tech_proj/data/all_untagged_data/test/test-m_pred_tech_terms.csv', index= False ,encoding='utf-8-sig')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CxDYMPsoHCxs"},"source":["input_dir = \"gdrive/My Drive/ner_tech_proj/saved_bert_model_and_tokenizer_m2_v15/\"\r\n","df_news = \"gdrive/My Drive/ner_tech_proj/data/all_untagged_data/test/test_model15.csv\"\r\n","df_test_tech_terms_news = detect_tech_terms_in_articles_csv(df_news, input_dir)\r\n","df_test_tech_terms_news.to_csv('gdrive/My Drive/ner_tech_proj/data/all_untagged_data/test/test_model15_pred_tech_terms.csv', index= False ,encoding='utf-8-sig')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UkDUI8pj1IvA","executionInfo":{"status":"ok","timestamp":1615777386724,"user_tz":240,"elapsed":26959,"user":{"displayName":"Shelley","photoUrl":"","userId":"14412474700598300757"}}},"source":["input_dir = \"gdrive/My Drive/ner_tech_proj/saved_bert_model_and_tokenizer_m2_v16/\"\r\n","df_news = \"gdrive/My Drive/ner_tech_proj/data/all_untagged_data/test/test2.csv\"\r\n","df_test_tech_terms_news = detect_tech_terms_in_articles_csv(df_news, input_dir)\r\n","df_test_tech_terms_news.to_csv('gdrive/My Drive/ner_tech_proj/data/all_untagged_data/test/test2_pred_tech_terms.csv', index= False ,encoding='utf-8-sig')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"kkJaxQiw2ZtE","executionInfo":{"status":"ok","timestamp":1615777638346,"user_tz":240,"elapsed":19369,"user":{"displayName":"Shelley","photoUrl":"","userId":"14412474700598300757"}}},"source":["input_dir = \"gdrive/My Drive/ner_tech_proj/saved_bert_model_and_tokenizer_m2_v12/\"\r\n","df_news = \"gdrive/My Drive/ner_tech_proj/data/all_untagged_data/test/test2.csv\"\r\n","df_test_tech_terms_news = detect_tech_terms_in_articles_csv(df_news, input_dir)\r\n","df_test_tech_terms_news.to_csv('gdrive/My Drive/ner_tech_proj/data/all_untagged_data/test/test2_pred_tech_terms_v12.csv', index= False ,encoding='utf-8-sig')"],"execution_count":5,"outputs":[]}]}